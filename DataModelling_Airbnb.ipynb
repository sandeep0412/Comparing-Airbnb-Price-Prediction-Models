{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataModelling_Airbnb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep0412/Comparing-Airbnb-Price-Prediction-Models/blob/master/DataModelling_Airbnb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_rGmY9_MAoVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import scipy.stats as stats\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
        "from sklearn.linear_model import LassoCV, RidgeCV\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold # import KFold\n",
        "from statistics import mean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glFC4YZVAzZb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listings_clean = pd.read_csv('/content/drive/My Drive/Colab Notebooks/listings_clean_a.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qg9WMw_cEdez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listings_clean.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7Ifu602P9Cc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "listings_price = listings_clean['price_log']\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "# data= np.zeros(X.shape[0])\n",
        "X = listings_train.as_matrix()\n",
        "y = listings_price.as_matrix()\n",
        "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  lreg_model = LinearRegression()\n",
        "  lreg_model.fit(X_train, y_train)\n",
        "  #lreg_model.get_params()\n",
        "  #print(X_test)\n",
        "  y_pred = lreg_model.predict(X_test)\n",
        "  #print(X_test)\n",
        "  # plot prediction and actual data\n",
        "  score.append(lreg_model.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  \n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCy7y7kROLsP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ridge Regression"
      ]
    },
    {
      "metadata": {
        "id": "EQJ0MuztG5X4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Ridge Regression\n",
        "listings_price = listings_clean['price_log']\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "# data= np.zeros(X.shape[0])\n",
        "X = listings_train.as_matrix()\n",
        "y = listings_price.as_matrix()\n",
        "lambdas = 10.**np.array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  #Ridge Regression\n",
        "  ridge_reg = linear_model.RidgeCV(alphas = lambdas, fit_intercept = False, normalize = True, cv = 5)\n",
        "  ridge_reg.fit(X_train, y_train) \n",
        "  ridge_reg.coef_\n",
        "  ridge_reg.intercept_ \n",
        "  y_pred = ridge_reg.predict(X_test)\n",
        "  #print(X_test)\n",
        "\n",
        "  # plot prediction and actual data\n",
        "  score.append(ridge_reg.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  \n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9Sk64xFHZ4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Bayesian Ridge Regression\n",
        "listings_price = listings_clean['price_log']\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "# data= np.zeros(X.shape[0])\n",
        "X = listings_train.as_matrix()\n",
        "y = listings_price.as_matrix()\n",
        "kf = KFold(n_splits=4) # Define the split - into 2 folds \n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  bridge_model = linear_model.BayesianRidge(compute_score=True)\n",
        "  bridge_model.fit(X_train, y_train)\n",
        "  bridge_model.get_params()\n",
        "\n",
        "  y_pred = bridge_model.predict(X_test)\n",
        "  #print(X_test)\n",
        "\n",
        "  # plot prediction and actual data\n",
        "  score.append(bridge_model.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  \n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zS9lYth4VIdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lasso Regression"
      ]
    },
    {
      "metadata": {
        "id": "8_Tb2Qv-IREF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lasso Regression\n",
        "listings_price = listings_clean['price_log']\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "# data= np.zeros(X.shape[0])\n",
        "X = listings_train.as_matrix()\n",
        "y = listings_price.as_matrix()\n",
        "kf = KFold(n_splits=4) # Define the split - into 2 folds \n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  lasso_model = linear_model.LassoCV()\n",
        "  lasso_model.fit(X_train, y_train)\n",
        "  lasso_model.get_params()\n",
        "\n",
        "  y_pred = lasso_model.predict(X_test)\n",
        "  #print(X_test)\n",
        "\n",
        "  # plot prediction and actual data\n",
        "  score.append(lasso_model.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  \n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3BVRlaTIna7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GradientBoostingRegression\n",
        "listings_price = listings_clean['price_log']\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "# data= np.zeros(X.shape[0])\n",
        "X = listings_train.as_matrix()\n",
        "y = listings_price.as_matrix()\n",
        "kf = KFold(n_splits=4) # Define the split - into 2 folds \n",
        "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  \n",
        "  gboost_model = GradientBoostingRegressor()\n",
        "  gboost_model.fit(X_train, y_train)\n",
        "  gboost_model.get_params()\n",
        "  y_pred = gboost_model.predict(X_test)\n",
        "  #print(X_test)\n",
        "\n",
        "  # plot prediction and actual data\n",
        "  score.append(gboost_model.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  \n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krb0i2eOPCQP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#listings_clean = cluster1.loc[cluster1['cluster'] == 1]\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "listings_price = listings_clean['price_log']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(listings_train, listings_price, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_DZi1SIO3kr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "\n",
        "\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "NN_model.summary()\n",
        "\n",
        "checkpoint_name = '/content/drive/My Drive/Colab Notebooks/Weights.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=0, mode='auto')\n",
        "callbacks_list = [checkpoint, earlystopping]\n",
        "\n",
        "NN_model.fit(X_train, Y_train, epochs=50, batch_size=15, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmBn-j7YPkZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predicted = NN_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import median_absolute_error\n",
        "median_absolute_error(Y_test, y_predicted)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8a4YhJnPlyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r2_score(Y_test, y_predicted) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dFdueKePvR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_absolute_error(Y_test, y_predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "damwh7eaa6tC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## After Clustering"
      ]
    },
    {
      "metadata": {
        "id": "ElylCPiAa-zR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#K-Means\n",
        "from sklearn.cluster import KMeans\n",
        "cluster1=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/listings_clean_a.csv\")\n",
        "listings_location = cluster1[['latitude', 'longitude']]\n",
        "listings_location.shape\n",
        "kmeans = KMeans(n_clusters=3, random_state=0).fit(listings_location)\n",
        "y_kmeans = kmeans.predict(listings_location)\n",
        "#kmeans.cluster_centers_\n",
        "\n",
        "cluster1['cluster'] = pd.Series(y_kmeans)\n",
        "plt.scatter(listings_location.longitude, listings_location.latitude, c=y_kmeans, cmap='viridis')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "print(centers)\n",
        "cluster1.to_csv('/content/drive/My Drive/Colab Notebooks/listings_clean_cluster_a.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWYQDO-f0TiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "meanerror=[]\n",
        "medianerror=[]\n",
        "score = []\n",
        "#Linear Regression CLuster\n",
        "for i in range(3):\n",
        "  listings_clean = cluster1.loc[cluster1['cluster'] == i]\n",
        "  listings_price = listings_clean['price_log']\n",
        "  listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "  # data= np.zeros(X.shape[0])\n",
        "  X = listings_train.as_matrix()\n",
        "  y = listings_price.as_matrix()\n",
        "  kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
        "  kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
        "  for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  lreg_model = LinearRegression()\n",
        "  lreg_model.fit(X_train, y_train)\n",
        "  #lreg_model.get_params()\n",
        "  #print(X_test)\n",
        "  y_pred = lreg_model.predict(X_test)\n",
        "  #print(X_test)\n",
        "  # plot prediction and actual data\n",
        "  score.append(lreg_model.score(X_test, y_test))\n",
        "  meanerror.append(mean_absolute_error(y_test, y_pred))\n",
        "  medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "  #medianerror.append(median_absolute_error(y_test, y_pred))\n",
        "\n",
        "# print(meanerror)\n",
        "# print(medianerror)\n",
        "\n",
        "print(mean(meanerror))\n",
        "print(mean(medianerror))\n",
        "print(score)\n",
        "print(mean(score))\n",
        "plt.plot(y_test, y_pred, '.')\n",
        "x1 = np.linspace(0, 700, 100)\n",
        "y1 = x1\n",
        "plt.plot(x1, y1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6zDbNWm5reD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listings_clean = cluster1.loc[cluster1['cluster'] == 1]\n",
        "listings_train = listings_clean.drop(columns=['price', 'price_log', 'id', 'host_id'])\n",
        "listings_price = listings_clean['price_log']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(listings_train, listings_price, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abSUnsok4p9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "\n",
        "\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(rate=0.1))\n",
        "\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "NN_model.summary()\n",
        "\n",
        "checkpoint_name = '/content/drive/My Drive/Colab Notebooks/Weights.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=0, mode='auto')\n",
        "callbacks_list = [checkpoint, earlystopping]\n",
        "\n",
        "NN_model.fit(X_train, Y_train, epochs=50, batch_size=15, validation_split = 0.2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82J5h5N17gpA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predicted = NN_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import median_absolute_error\n",
        "median_absolute_error(Y_test, y_predicted)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88wu9Zr275UF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r2_score(Y_test, y_predicted) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX_Cawj_9YVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_absolute_error(Y_test, y_predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}